# Copyright (c) 2018-2022, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

ARG BASE_IMAGE
FROM ${BASE_IMAGE}

SHELL ["/bin/bash", "-c"]

ARG CUDA_VER=11.6
ARG USE_NIGHTLY=1
# Install core packages
RUN apt update \
 && apt install -y --no-install-recommends build-essential autoconf libtool git \
        ccache curl wget pkg-config sudo ca-certificates automake libssl-dev \
        bc python3-dev python3-pip google-perftools gdb libglib2.0-dev clang sshfs libre2-dev \
        libboost-dev libnuma-dev numactl sysstat sshpass ntpdate less vim iputils-ping \
 && apt remove -y cmake \
 && apt remove -y libgflags-dev \
 && apt remove -y libprotobuf-dev \
 && apt -y autoremove
RUN apt install -y --no-install-recommends pkg-config zip g++ zlib1g-dev unzip

RUN DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends cmake

# For pillow
RUN apt-get install -y --no-install-recommends libjpeg-dev zlib1g-dev

# Install dependencies needed for RNN-T preprocessing
RUN apt-get update && apt-get install -y sox llvm llvm-dev

# Needed by official RNNT accuracy script
RUN apt install -y --no-install-recommends libsndfile1-dev

# Install rapidJSON, needed by Triton
RUN apt install rapidjson-dev

# For onnx
RUN apt-get install -y --no-install-recommends protobuf-compiler libprotoc-dev

# For h5py
RUN apt-get install -y libhdf5-serial-dev hdf5-tools

COPY requirements.aarch64.1.txt requirements.aarch64.2.txt /tmp
WORKDIR /tmp

# Set up basic setuptools for pip install commands.
RUN python3 -m pip install --upgrade pip \
 && python3 -m pip install --upgrade setuptools wheel virtualenv Cython==0.29.23

# Break requirements into two lists because some of them require that other packages be fully installed first.
RUN python3 -m pip install -r requirements.aarch64.1.txt \
 && python3 -m pip install -r requirements.aarch64.2.txt

# Install HuggingFace Transformers
RUN curl https://sh.rustup.rs -sSf | sh -s -- -y \
 && export PATH=$HOME/.cargo/bin:$PATH \
 && python3 -m pip install transformers==4.6.0

# install gflags
# -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=ON .. \
RUN git clone -b v2.2.1 https://github.com/gflags/gflags.git \
 && cd gflags \
 && mkdir build && cd build \
 && cmake -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=ON .. \
 && make -j \
 && make install \
 && cd /tmp && rm -rf gflags

# install glog
RUN git clone -b v0.3.5 https://github.com/google/glog.git \
 && cd glog \
 && cmake -H. -Bbuild -G "Unix Makefiles" -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON \
 && cmake --build build \
 && cmake --build build --target install \
 && cd /tmp && rm -rf glog

# Install CUB, needed by NMS OPT plugin
RUN wget https://github.com/NVlabs/cub/archive/1.8.0.zip -O cub-1.8.0.zip \
 && unzip cub-1.8.0.zip \
 && mv cub-1.8.0/cub /usr/include/aarch64-linux-gnu/ \
 && rm -rf cub-1.8.0.zip cub-1.8.0

# Install libjemalloc2
RUN echo 'deb [arch=aarch64] http://archive.ubuntu.com/ubuntu focal main restricted universe multiverse' | tee -a /etc/apt/sources.list.d/focal.list \
  && echo 'Package: *\nPin: release a=focal\nPin-Priority: -10\n' | tee -a /etc/apt/preferences.d/focal.pref \
  && apt update \
  && apt install --no-install-recommends -t focal -y libjemalloc2 libtcmalloc-minimal4

# Install cudnn 8.2.1.32 to match TensorRT rel-8.0
ARG CUDNN_DEB_URL=https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/
RUN cd /tmp \
 && install_deb_pkg() { wget $CUDNN_DEB_URL/$1 -O $1 && dpkg -i $1 && rm $1; } \
 && install_deb_pkg libcudnn8_8.4.0.27-1+cuda11.6_arm64.deb \
 && install_deb_pkg libcudnn8-dev_8.4.0.27-1+cuda11.6_arm64.deb \
 && unset -f install_deb_pkg

# Remove the default TRT 7.2 installation in the cudnn container
RUN rm -rf /usr/local/lib/python3.8/dist-packages/tensorrt/

# Install TRT 8.4 nightly
# ARG TRT_NIGHTLY_URL=https://urm.nvidia.com/artifactory/sw-tensorrt-generic/cicd/rel-8.4/LR_EveryKDays/26/trt_build_aarch64_ubuntu20.04_cuda${CUDA_VER}_release_optimized.tar
# RUN if [ $USE_NIGHTLY = 1 ]; then \
#     cd /tmp \
#     && wget ${TRT_NIGHTLY_URL} --user tensorrt-read-only --password "Tensorrt@123" -O TRT.tar \
#     && tar -xvf TRT.tar \
#     && cd source/install/aarch64-gnu \
#     && mkdir trt \
#     && tar -xvzf cuda-${CUDA_VER}/release_tarfile/TensorRT-*.Ubuntu-20.04.aarch64-gnu.cuda-${CUDA_VER}.cudnn*.tar.gz -C trt --strip-components 1 \
#     && tar -xvzf TensorRT-*.Ubuntu-20.04.aarch64-gnu.cuda-${CUDA_VER}.internal.tar.gz -C trt --strip-components 1 \
#     && cp -rv trt/lib/* /usr/lib/aarch64-linux-gnu/ \
#     && cp -rv trt/include/* /usr/include/aarch64-linux-gnu/ \
#     && cp -rv trt/bin/* /usr/bin/ \
#     && python3 -m pip install trt/uff/*.whl trt/graphsurgeon/*.whl trt/python/tensorrt-*-cp38-none-linux_aarch64.whl \
#     && cd ../../.. \
#     && rm -rf source \
#     && rm -f TRT.tar; fi

# Install TRT 8.4.2 RC
ARG TRT_DEB_URL=http://cuda-repo/release-candidates/Libraries/TensorRT/v8.4/8.4.2.4-d392144b/11.6-r510/Ubuntu20_04-aarch64/deb/
ARG TRT_MAJOR_VER=8
ARG TRT_MINOR_VER=4
ARG TRT_PATCH_VER=2
ARG TRT_VER=${TRT_MAJOR_VER}.${TRT_MINOR_VER}.${TRT_PATCH_VER}
RUN if [ $USE_NIGHTLY = 1 ]; then \
    cd /tmp \
    && install_deb_pkg() { wget $TRT_DEB_URL/$1 -O $1 && dpkg -i $1 && rm $1; } \
    && install_deb_pkg libnvinfer${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvinfer-dev_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvinfer-plugin${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvinfer-plugin-dev_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvparsers${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvparsers-dev_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvonnxparsers${TRT_MAJOR_VER}_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg libnvonnxparsers-dev_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg python3-libnvinfer_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && install_deb_pkg python3-libnvinfer-dev_${TRT_VER}-1+cuda${CUDA_VER}_arm64.deb \
    && unset -f install_deb_pkg; fi


# Install public version if USE_NIGHTLY is 0
# ARG TRT_DEB_URL=https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/
RUN if [ $USE_NIGHTLY = 0 ]; then \
    cd /tmp \
    && wget https://developer.download.nvidia.com/compute/machine-learning/tensorrt/8.4.0/local_repos/nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.0.6-ea-20220212_1-1_arm64.deb \
    && sudo dpkg -i nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.0.6-ea-20220212_1-1_arm64.deb \
    && sudo apt-key add /var/nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.0.6-ea-20220212/7fa2af80.pub \
    && sudo apt update \
    && sudo apt install -y libnvinfer8 libnvinfer-dev libnvinfer-plugin8 libnvinfer-plugin-dev libnvparsers8 \
                libnvparsers-dev libnvonnxparsers8 libnvonnxparsers-dev libnvonnxparsers-dev python3-libnvinfer-dev \
    && rm nv-tensorrt*.deb; fi


# With latest Ubuntu:20.04 container, there will be no 'python' or 'pip' even if we have installed 'python3' and
# 'python3-pip'. So add softlink to avoid wheel installation failure.
RUN ln -sf /usr/bin/python3 /usr/bin/python
RUN ln -sf /usr/bin/pip3 /usr/bin/pip

WORKDIR /work
