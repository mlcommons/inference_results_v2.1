# MLPerf Inference v2.1 - Krai - Quantization Details

## TFLite/ArmNN results

We use quantized TFLite models shared by Google.
We believe that Google used [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) via the [TFLite converter](https://www.tensorflow.org/lite/convert/).
